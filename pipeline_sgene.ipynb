{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ad45e1d-b15b-4233-b6a5-afe45f3a38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769c8df-1be4-4ee4-95aa-08b402349e99",
   "metadata": {},
   "source": [
    "# Pipeline:\n",
    "\n",
    "- prepare sample table\n",
    "- run trimming to remove adapters and primers\n",
    "- run dada2 to generate ASVs, remove chimeras, and abundance table\n",
    "- run nextclade to call SNVs and indels\n",
    "\n",
    "\n",
    "TO-DO:\n",
    "\n",
    "Turn pipeline into an executable that takes sample table as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8367ca-cd38-46c7-b138-c124f7a5a403",
   "metadata": {},
   "source": [
    "# Set up sample directory\n",
    "1. download reads into data/raw\n",
    "2. make read_list.txt (ls \\*R1\\*.fastq.gz > reads_list.txt)\n",
    "3. make subdirectories within data/raw for each amplicon\n",
    "4. make trimmed_reads directories for each amplicon (e.g. data/raw/trimmed_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708ddb8-7350-40ac-91fb-71bb2eb33af8",
   "metadata": {},
   "source": [
    "# Make sample table (can do this in a spreadsheet or here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62e65e-36a9-42a0-83c7-3de022e8e1e4",
   "metadata": {},
   "source": [
    "**sample table must have columns:**\n",
    "\n",
    "- read1 # basename of read file 1 (e.g. \"NTD_I_I_INF_101321_1_S58_L001_R2_001.fastq.gz\")\n",
    "- read2 # created off of read1\n",
    "- amplicon # extracted from read1 (e.g. \"NTD\")\n",
    "- sample_id # extracted from read1, following lab convention (e.g. \"I_I_INF_101321_1\")\n",
    "- merge_id # same as sample_id, or a replicate sample with a Cq value in qPCR table (if the sample sent for sequencing was not analyzed via qPCR)\n",
    "- treatment # any upstream non-standard treatment performed on the sample or RNA (e.g. \"rRd\" for RNA depletion)\n",
    "- datadir # location of read1 and read2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "62848b6e-0e70-4ea6-b286-8e6144d674c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10/4/21\n",
    "# # samples given to Justin were run with RBD primers only and were processed with rRNA depletion ('rRd') or without ('STD')\n",
    "# # samples run in-house were labeled \"RBD\"\n",
    "\n",
    "datadir = '/Users/rosekantor/data/wbe_scv/qb3_sgene_100421'\n",
    "reads_df = pd.read_csv(f'{datadir}/raw/reads_list.txt', names=['read1'])\n",
    "\n",
    "reads_df = reads_df[~reads_df.read1.str.contains('Undetermined')]\n",
    "reads_df['read2'] = reads_df.read1.str.replace(r'_R1_', '_R2_')\n",
    "reads_df[['amplicon','sample_id']] = reads_df.read1.str.extract(r'(\\w+)_(.+_.+_.+_\\d+_\\d+)_S\\d+_L001_R._001\\.fastq\\.gz')\n",
    "reads_df['merge_id'] = reads_df['sample_id'].copy()\n",
    "reads_df['treatment'] = 'inhouse'\n",
    "reads_df.loc[reads_df.amplicon == 'rRd', 'treatment'] = 'rRd'\n",
    "reads_df.loc[reads_df.treatment == 'rRd', 'amplicon'] = 'RBD' # rename amplicon, all ribodepleted samples were RBD this round\n",
    "reads_df.loc[reads_df.amplicon == 'STD', 'treatment'] = 'std'\n",
    "reads_df.loc[reads_df.amplicon == 'STD', 'amplicon'] = 'RBD' # the non-ribodepleted amplicons from FGL were RBD but got named \"STD\" for standard treatment\n",
    "reads_df['datadir'] = datadir\n",
    "\n",
    "# In this run, the same samples were run with and without ribodepletion. Give these unique names:\n",
    "reads_df.loc[reads_df.treatment.isin(['std', 'rRd']), 'sample_id'] = reads_df.treatment + \"_\" + reads_df.sample_id\n",
    "\n",
    "reads_df.to_csv(f'{datadir}/sample_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2786e30c-32f5-40bf-bc35-fff5edc5a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11/5/21\n",
    "# samples all processed with rRNA depletion at FGL/GSL\n",
    "\n",
    "datadir = '/Users/rosekantor/data/wbe_scv/qb3_sgene_110521'\n",
    "reads_df = pd.read_csv(f'{datadir}/raw/reads_list.txt', names=['read1'])\n",
    "\n",
    "reads_df = reads_df[~reads_df.read1.str.contains('Undetermined')]\n",
    "reads_df['read2'] = reads_df.read1.str.replace(r'_R1_', '_R2_')\n",
    "reads_df['read_name'] = reads_df.read1.str.replace('control', 'control_control') # control got misnamed, needs to say control_control to match pattern\n",
    "reads_df['read_name'] = reads_df.read_name.str.replace('Twist_2_23', 'control_Twist_2_23_101521') # to match pattern\n",
    "reads_df[['amplicon','sample_id']] = reads_df.read_name.str.extract(r'(\\w+)_(.+_.+_.+_\\d+_\\d+)_S\\d+_L001_R._001\\.fastq\\.gz')\n",
    "reads_df['merge_id'] = reads_df['sample_id'].copy()\n",
    "reads_df['treatment'] = 'rRd' # all were ribodepleted\n",
    "reads_df['datadir'] = datadir\n",
    "\n",
    "reads_df.to_csv(f'{datadir}/sample_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d048d29-8143-4ba7-a606-9086ee0edb6b",
   "metadata": {},
   "source": [
    "# Generate commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3b8c04f0-c25d-4f6c-9a5e-daaee15de2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_df = pd.read_csv('/Users/rosekantor/data/wbe_scv/qb3_sgene_110521/sample_table.csv')\n",
    "# reads_df = pd.read_csv('/Users/rosekantor/data/wbe_scv/qb3_sgene_100421/sample_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "81014a47-2ebe-43b9-988b-aca660f0d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim adapters and primers with cutadapt, specific to the primers used\n",
    "\n",
    "# dict of fwd and rev trimming sequences\n",
    "trim_seqs = {'RBD':['GTGATGAAGTCAGACAAATCGC...CAGACACTTGAGATTCTTGACAT', \n",
    "                    'ATGTCAAGAATCTCAAGTGTCTG...GCGATTTGTCTGACTTCATCAC'],\n",
    "             'NTD':['GCGATTTGTCTGACTTCATCAC...TTTCGGCTTTAGAACCATTGG',\n",
    "                    'CCAATGGTTCTAAAGCCGAAA...AAGAACAAGTCCTGAGTTGAATG'],\n",
    "             'S1S2':['CAGGCACAGGTGTTCTTACT...CTACCAGTGTCTATGACCAAGAC',\n",
    "                     'GTCTTGGTCATAGACACTGGTAG...AGTAAGAACACCTGTGCCTG']}\n",
    "\n",
    "trim_cmd = []\n",
    "for r in reads_df.itertuples():\n",
    "    raw_path = f'{r.datadir}/raw'\n",
    "    amplicon = r.amplicon\n",
    "    trimmedF = f'{raw_path}/{amplicon.lower()}/trimmed_reads/{r.sample_id}.1.fastq.gz'\n",
    "    trimmedR = f'{raw_path}/{amplicon.lower()}/trimmed_reads/{r.sample_id}.2.fastq.gz'\n",
    "    \n",
    "    cutadapt_cmd = f'cutadapt -a {trim_seqs[amplicon][0]} -A {trim_seqs[amplicon][1]} --discard-untrimmed -o {trimmedF} -p {trimmedR} {raw_path}/{r.read1} {raw_path}/{r.read2}'\n",
    "    \n",
    "    trim_cmd.append(cutadapt_cmd)\n",
    "\n",
    "reads_df['trim_cmd'] = trim_cmd\n",
    "\n",
    "# save commands\n",
    "datadir = reads_df.datadir.values[0]\n",
    "reads_df.trim_cmd.to_csv(f'{datadir}/read_trimming.sh', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "95b1b23a-ffb7-40f5-9543-0c2d3a8b36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write commands for dada2 pipeline and nextclade\n",
    "\n",
    "amplicons = ['NTD', 'RBD', 'S1S2']\n",
    "datadir = reads_df.datadir.values[0]\n",
    "dada2_pipeline = '/Users/rosekantor/work/wbe_sequence_analysis/dada2_pipeline.R'\n",
    "nextclade = '/Users/rosekantor/work/wbe_sequence_analysis/nextclade'\n",
    "nextclade_ref = '/Users/rosekantor/work/wbe_sequence_analysis/nextclade_data/sars-cov-2'\n",
    "dada2_out = f'{datadir}/results/dada2_out'\n",
    "nextclade_out = f'{datadir}/results/nextclade_out'\n",
    "\n",
    "# NOTE: trimmed reads from each amplicon need to be in separate folders for dada2 to run on one amplicon at a time\n",
    "\n",
    "with open(f'{datadir}/analysis_cmds.sh', 'w') as f:\n",
    "    # option ot update nextclade and ref dataset\n",
    "    # f.write('cd /Users/rosekantor/work/wbe_sequence_analysis\\n')\n",
    "    # f.write('curl -fsSL \"https://github.com/nextstrain/nextclade/releases/latest/download/nextclade-MacOS-arm64\" -o \"nextclade\" && chmod +x nextclade\\n')\n",
    "    # f.write('/Users/rosekantor/work/wbe_sequence_analysis/nextclade dataset get --name \"sars-cov-2\" --output-dir \"nextclade_data/sars-cov-2\"\\n')\n",
    "\n",
    "    f.write(f'mkdir {datadir}/results\\n')\n",
    "    f.write(f'mkdir {dada2_out}\\n')\n",
    "    f.write(f'mkdir {nextclade_out}\\n')\n",
    "    for amplicon in amplicons: \n",
    "        trimmed_path = f'{datadir}/raw/{amplicon.lower()}/trimmed_reads/'\n",
    "        dada2_cmd = f'/Users/rosekantor/work/wbe_sequence_analysis/dada2_pipeline.R {amplicon} {trimmed_path} {dada2_out}'\n",
    "        nextclade_cmd = f'{nextclade} --in-order --input-fasta {dada2_out}/{amplicon}_dada2_out.fasta --input-dataset {nextclade_ref} --output-csv {nextclade_out}/{amplicon}_nextclade.csv --output-dir {nextclade_out}'\n",
    "        f.write(dada2_cmd + '\\n')\n",
    "        f.write(nextclade_cmd + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8af616-44cf-4f48-9c12-4df3db78cbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
